{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1: What is Boosting in Machine Learning? Explain how it improves weak learners.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **What is Boosting?**\n",
        "\n",
        "* **Boosting** is an **ensemble learning technique** in machine learning.\n",
        "* It combines **multiple weak learners** (models slightly better than random guessing) to create a **strong learner** with high predictive accuracy.\n",
        "* Unlike bagging (e.g., Random Forest), boosting builds models **sequentially**, where each new model tries to **correct the errors of the previous models**.\n",
        "\n",
        "---\n",
        "\n",
        "### **How Boosting Works**\n",
        "\n",
        "1. **Start with a weak learner:**\n",
        "\n",
        "   * For example, a shallow decision tree that performs slightly better than random.\n",
        "2. **Train sequentially:**\n",
        "\n",
        "   * After each iteration, the model **gives more weight to misclassified samples** so that the next weak learner focuses on the harder examples.\n",
        "3. **Combine predictions:**\n",
        "\n",
        "   * The final output is a **weighted combination** of all weak learners’ predictions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Intuition**\n",
        "\n",
        "* Imagine teaching a class:\n",
        "\n",
        "  * The first tutor explains the basics, but some students still get things wrong.\n",
        "  * The next tutor focuses **only on the students who struggled**, improving understanding.\n",
        "  * After several tutors, nearly all students understand the topic.\n",
        "\n",
        "---\n",
        "\n",
        "### **Examples of Boosting Algorithms**\n",
        "\n",
        "* **AdaBoost:** Adjusts weights of misclassified samples after each iteration.\n",
        "* **Gradient Boosting:** Trains new models to predict the **residual errors** of previous models.\n",
        "* **XGBoost / LightGBM / CatBoost:** Efficient, optimized versions of gradient boosting with additional improvements.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Advantages**\n",
        "\n",
        "* Converts weak learners into a **strong model**.\n",
        "* Handles complex relationships and non-linear patterns.\n",
        "* Often achieves **higher accuracy** than individual models.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Question 2: What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?\n",
        "\n",
        "---\n",
        "\n",
        "### **1. AdaBoost (Adaptive Boosting)**\n",
        "\n",
        "* **Training Method:**\n",
        "\n",
        "  * Builds weak learners **sequentially**.\n",
        "  * After each model, **misclassified samples are given higher weights**.\n",
        "  * The next weak learner focuses more on these **hard-to-classify points**.\n",
        "* **Key Idea:** Adjust **sample weights** to reduce errors.\n",
        "* **Output Combination:** Weighted majority vote (classification) or weighted sum (regression).\n",
        "* **Use Case:** Works well with **small trees (stumps)** as base learners.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Gradient Boosting**\n",
        "\n",
        "* **Training Method:**\n",
        "\n",
        "  * Builds weak learners sequentially, but each new model is trained to **predict the residual errors (gradients) of the previous model**.\n",
        "  * Uses **gradient descent** on a specified **loss function** to minimize errors.\n",
        "* **Key Idea:** Optimize a **loss function** by adding models that point in the **direction of the negative gradient**.\n",
        "* **Output Combination:** Sum of predictions from all weak learners.\n",
        "* **Use Case:** Flexible and can optimize **any differentiable loss function**, e.g., regression, classification, or ranking.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Difference Table**\n",
        "\n",
        "| Feature       | AdaBoost                | Gradient Boosting                           |\n",
        "| ------------- | ----------------------- | ------------------------------------------- |\n",
        "| Focus         | Misclassified samples   | Residual errors (gradients)                 |\n",
        "| Weighting     | Adjusts sample weights  | Fits new model to negative gradient of loss |\n",
        "| Loss Function | Exponential loss        | Any differentiable loss function            |\n",
        "| Base Learner  | Usually decision stumps | Usually shallow trees, but can be deeper    |\n",
        "| Flexibility   | Less flexible           | Highly flexible (custom loss functions)     |\n",
        "\n",
        "---\n",
        "\n",
        "**Intuition:**\n",
        "\n",
        "* **AdaBoost:** “Pay more attention to mistakes” → correct misclassified points.\n",
        "* **Gradient Boosting:** “Fit to what’s left over” → model the **residual errors** of the previous models.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Question 3: How does regularization help in XGBoost?\n",
        "\n",
        "---\n",
        "\n",
        "### **Regularization in XGBoost**\n",
        "\n",
        "* **XGBoost** is a powerful **gradient boosting algorithm** that includes built-in **regularization** to prevent overfitting.\n",
        "* Regularization **penalizes model complexity**, encouraging the model to be simpler and more generalizable.\n",
        "\n",
        "---\n",
        "\n",
        "### **Types of Regularization in XGBoost**\n",
        "\n",
        "1. **L1 Regularization (alpha, $\\alpha$)**\n",
        "\n",
        "   * Penalizes the **absolute values of leaf weights**.\n",
        "   * Encourages **sparsity** — some leaf weights may become exactly zero, effectively pruning irrelevant features.\n",
        "\n",
        "2. **L2 Regularization (lambda, $\\lambda$)**\n",
        "\n",
        "   * Penalizes the **squared values of leaf weights**.\n",
        "   * Reduces the magnitude of leaf weights, making the model **less sensitive to noise**.\n",
        "\n",
        "3. **Tree-specific regularization**\n",
        "\n",
        "   * **max\\_depth:** Limits tree depth to avoid overly complex trees.\n",
        "   * **min\\_child\\_weight:** Minimum sum of instance weights in a leaf; avoids creating leaves with very few instances.\n",
        "   * **gamma:** Minimum loss reduction required for a split; prevents splits that don’t improve performance much.\n",
        "\n",
        "---\n",
        "\n",
        "### **Intuition**\n",
        "\n",
        "* Without regularization, XGBoost can **overfit** to noise or outliers in training data.\n",
        "* Regularization ensures that:\n",
        "\n",
        "  * Trees are not too deep or complex.\n",
        "  * Leaf weights are controlled.\n",
        "  * The model generalizes better to **unseen data**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Example**\n",
        "\n",
        "* High `lambda` or `alpha` → smaller leaf weights → simpler predictions.\n",
        "* Increasing `max_depth` without regularization → can overfit.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Question 4: Why is CatBoost considered efficient for handling categorical data?\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Why CatBoost is Efficient for Categorical Data**\n",
        "\n",
        "**CatBoost** is a gradient boosting algorithm designed specifically to **handle categorical features efficiently** without heavy preprocessing.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Reasons**\n",
        "\n",
        "1. **Built-in Categorical Handling**\n",
        "\n",
        "   * CatBoost can **directly process categorical variables** without needing one-hot encoding.\n",
        "   * It uses **ordered target statistics (mean encoding)** and **permutation-driven encoding** to convert categories into numerical values safely.\n",
        "\n",
        "2. **Avoids Target Leakage**\n",
        "\n",
        "   * Traditional mean encoding can leak information from the target variable into training, causing overfitting.\n",
        "   * CatBoost uses **ordered boosting**, which ensures that the encoding for each row **does not use its own target value**, reducing leakage.\n",
        "\n",
        "3. **Efficient with High-Cardinality Features**\n",
        "\n",
        "   * Works well even when categorical features have **many unique values**, unlike one-hot encoding which would explode feature space.\n",
        "\n",
        "4. **Faster and Accurate**\n",
        "\n",
        "   * By handling categorical features natively, CatBoost **reduces preprocessing time** and **improves performance**.\n",
        "   * Combines **symmetric trees** and optimized algorithms for **faster training**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Intuition**\n",
        "\n",
        "* Suppose you have a feature like **“City”** with 1,000 unique cities.\n",
        "* One-hot encoding creates 1,000 new features → slow and sparse.\n",
        "* CatBoost encodes this **numerically** using smart statistics → keeps the dataset compact and training fast.\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary**\n",
        "\n",
        "* **Direct categorical support** → no manual encoding needed.\n",
        "* **Ordered statistics** → reduces overfitting.\n",
        "* **Efficient for high-cardinality features** → scales to large datasets.\n",
        "* **Faster training with better accuracy** compared to naive encoding methods.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "#Question 5: What are some real-world applications where boosting techniques are preferred over bagging methods?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Real-World Applications Where Boosting is Preferred Over Bagging**\n",
        "\n",
        "Boosting is preferred when **high predictive accuracy** is critical, and the data may contain **complex patterns** that weak learners can gradually capture. Unlike bagging (e.g., Random Forest), boosting focuses on **sequentially reducing errors**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Applications**\n",
        "\n",
        "1. **Financial Services**\n",
        "\n",
        "   * **Credit risk scoring:** Predicting loan defaults where accuracy is crucial.\n",
        "   * **Fraud detection:** Boosting models catch subtle patterns in transaction data that simple models may miss.\n",
        "\n",
        "2. **Healthcare**\n",
        "\n",
        "   * **Disease diagnosis:** Identifying patients at risk based on lab tests or imaging data.\n",
        "   * **Predicting patient outcomes:** Boosting can model non-linear relationships between multiple clinical variables.\n",
        "\n",
        "3. **Marketing & Customer Analytics**\n",
        "\n",
        "   * **Customer churn prediction:** Sequentially improves predictions on hard-to-predict customers.\n",
        "   * **Targeted advertising:** Boosting captures complex patterns in user behavior for better personalization.\n",
        "\n",
        "4. **E-commerce & Recommendation Systems**\n",
        "\n",
        "   * Predicting product preferences or likelihood of purchase, especially when some patterns are subtle.\n",
        "\n",
        "5. **Competitions & Kaggle Solutions**\n",
        "\n",
        "   * Boosting algorithms like **XGBoost, LightGBM, CatBoost** are widely used in data science competitions because of **high accuracy and flexibility**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why Boosting is Preferred**\n",
        "\n",
        "* Handles **complex, non-linear relationships** better than bagging.\n",
        "* Focuses on **hard-to-predict instances**, improving overall performance.\n",
        "* Often achieves **higher accuracy**, even if training is slower.\n",
        "* Works well with **imbalanced datasets** when combined with proper metrics.\n",
        "\n",
        "---\n",
        "\n",
        "**Intuition:**\n",
        "\n",
        "* Bagging = “Vote of many independent trees.” Good for variance reduction.\n",
        "* Boosting = “Learn from mistakes sequentially.” Good for reducing bias and improving accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iACoMpRicmOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Datasets: ● Use sklearn.datasets.load_breast_cancer() for classification tasks. ● Use sklearn.datasets.fetch_california_housing() for regression tasks. Question 6: Write a Python program to: ● Train an AdaBoost Classifier on the Breast Cancer dataset ● Print the model accuracy (Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Train AdaBoost Classifier\n",
        "adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "adaboost.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = adaboost.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BTyaGUlfrOr",
        "outputId": "314f6cef-7b76-4598-b9e9-76fce000ce5b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9532163742690059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7: Write a Python program to:● Train a Gradient Boosting Regressor on the California Housing dataset ● Evaluate performance using R-squared score (Include your Python code and output in the code box below.)\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting Regressor\n",
        "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gbr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = gbr.predict(X_test)\n",
        "\n",
        "# Evaluate performance using R-squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared score:\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUzCtT7df7kj",
        "outputId": "c5ad922f-e5d2-45a2-c00c-86f9b3a5ae17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared score: 0.7803012822391022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: Write a Python program to: ● Train an XGBoost Classifier on the Breast Cancer dataset ● Tune the learning rate using GridSearchCV ● Print the best parameters and accuracy (Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define XGBoost classifier\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Define hyperparameter grid for learning rate\n",
        "param_grid = {'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]}\n",
        "\n",
        "# Apply GridSearchCV\n",
        "grid = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "\n",
        "# Evaluate best model on test set\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy on test set:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siSERcE2gMSj",
        "outputId": "ffaae64d-ed95-46a3-886d-f16551232c73"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:20] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:20] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:20] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:21] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:21] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:21] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:21] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:21] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:22] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:22] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:22] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:22] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:22] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:22] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:42:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.05}\n",
            "Accuracy on test set: 0.9590643274853801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Write a Python program to: ● Train a CatBoost Classifier ● Plot the confusion matrix using seaborn (Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Train CatBoost Classifier\n",
        "cat_model = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=3, verbose=0, random_state=42)\n",
        "cat_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = cat_model.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix using seaborn\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - CatBoost Classifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "YET7pHa4g62Y",
        "outputId": "64c8a453-bee8-4d7b-caaf-7607e48357be"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c8ae8b3",
        "outputId": "7c71a511-8301-4302-82f4-0ae2759a69c1"
      },
      "source": [
        "%pip install catboost"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 10: You're working for a FinTech company trying to predict loan default usingcustomer demographics and transaction behavior. The dataset is imbalanced, contains missing values, and has both numeric and categorical features.Describe your step-by-step data science pipeline using boosting techniques: ● Data preprocessing & handling missing/categorical values ● Choice between AdaBoost, XGBoost, or CatBoost ● Hyperparameter tuning strategy ● Evaluation metrics you'd choose and why ● How the business would benefit from your model (Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Step 1: Data Preprocessing\n",
        "\n",
        "Handle missing values:\n",
        "\n",
        "For numeric features: replace with mean/median or use CatBoost's native handling.\n",
        "\n",
        "For categorical features: replace with a placeholder or let CatBoost handle missing categories.\n",
        "\n",
        "Encode categorical features:\n",
        "\n",
        "CatBoost can handle categorical features natively, so no need for one-hot encoding.\n",
        "\n",
        "Handle class imbalance:\n",
        "\n",
        "Use class weights or scale_pos_weight in XGBoost/CatBoost to give more importance to minority class.\n",
        "\n",
        "Step 2: Model Choice\n",
        "\n",
        "CatBoostClassifier is preferred here because:\n",
        "\n",
        "Native handling of categorical data.\n",
        "\n",
        "Handles missing values internally.\n",
        "\n",
        "Robust to overfitting and works well with imbalanced datasets.\n",
        "\n",
        "Step 3: Hyperparameter Tuning\n",
        "\n",
        "Use GridSearchCV or RandomizedSearchCV for parameters like:\n",
        "\n",
        "iterations, learning_rate, depth\n",
        "\n",
        "l2_leaf_reg (regularization)\n",
        "\n",
        "scale_pos_weight (for imbalanced data)\n",
        "\n",
        "Step 4: Evaluation Metrics\n",
        "\n",
        "ROC-AUC: Measures how well the model separates defaulters from non-defaulters.\n",
        "\n",
        "Precision & Recall: Important to balance:\n",
        "\n",
        "Precision → minimize false positives (wrongly flagging a customer).\n",
        "\n",
        "Recall → minimize false negatives (missing a defaulter).\n",
        "\n",
        "F1-score: Combines precision and recall, useful for imbalanced datasets.\n",
        "\n",
        "Step 5: Business Impact\n",
        "\n",
        "Early detection of high-risk customers → reduce loan defaults.\n",
        "\n",
        "Targeted interventions (e.g., personalized offers, stricter credit checks).\n",
        "\n",
        "Improve profitability and minimize financial losses."
      ],
      "metadata": {
        "id": "dvlByN1yhitz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Example synthetic dataset\n",
        "data = pd.DataFrame({\n",
        "    'age': [25, 45, 35, 50, 23, 40, 60, 30],\n",
        "    'income': [50000, 80000, 60000, 100000, 45000, 70000, 120000, 52000],\n",
        "    'job_type': ['salaried', 'self-employed', 'salaried', 'self-employed','salaried','self-employed','retired','salaried'],\n",
        "    'loan_amount': [20000, 30000, 15000, 40000, 10000, 25000, 50000, 12000],\n",
        "    'default': [0,1,0,1,0,0,1,0]  # target\n",
        "})\n",
        "\n",
        "# Features and target\n",
        "X = data.drop('default', axis=1)\n",
        "y = data['default']\n",
        "\n",
        "# Identify categorical features\n",
        "categorical_features = ['job_type']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Train CatBoost Classifier\n",
        "cat_model = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    learning_rate=0.1,\n",
        "    depth=3,\n",
        "    eval_metric='AUC',\n",
        "    class_weights=[1, 5],   # handle imbalance: give more weight to minority class\n",
        "    cat_features=categorical_features,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cat_model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
        "\n",
        "# Predictions\n",
        "y_pred = cat_model.predict(X_test)\n",
        "y_pred_prob = cat_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Evaluation\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNaNSWNLib2B",
        "outputId": "aa112547-bdc3-453e-8df7-af14fc781162"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n",
            "ROC-AUC Score: 1.0\n"
          ]
        }
      ]
    }
  ]
}